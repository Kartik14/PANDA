# -*- coding: utf-8 -*-
"""Copy of train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1910MASQd7ZZdpgfl0XfwWxtjGAvftScY

# Imports
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import time
import skimage
import numpy as np
import pandas as pd
from PIL import Image, ImageOps
from sklearn.model_selection import StratifiedKFold
import matplotlib.pyplot as plt
from sklearn.metrics import cohen_kappa_score
from tqdm import tqdm
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader, Dataset
from efficientnet_pytorch import EfficientNet
from warmup_scheduler import GradualWarmupScheduler
from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler
import fcn
import scipy
# %cd apex
from apex import amp
Image.MAX_IMAGE_PIXELS = None
print(torch.cuda.device_count())
"""# Configs"""

data_dir = '../data/'
BASE = '/home1/sriram/panda/train_images'
SEG_BASE = '/home1/sriram/panda/'
TRAIN = 'train_images/'
OUT_TRAIN = 'train_images_2'
SEG = 'image_masks'
OUT_SEG = 'out_masks'
df_biopsy = pd.read_csv(os.path.join(BASE, '../train_available_2.csv'))
image_folder = os.path.join(data_dir, 'train_images_tiles_36_256x256')
kernel_type = 'efficientnet-b0-36_256x256'
kernel_type2 = 'half_fcn'
enet_type = 'efficientnet-b0'
fold = 0
tile_size = 256
image_size = 256
n_tiles = 36
batch_size = 1
num_workers = 8
out_dim = 5
init_lr =  4 * 1e-3
warmup_factor = 10
pretrained = '/home1/sriram/panda/saved_models/efficientnet-b0-36_256x256_t_fold-0_best.pth'
pretrained2 = '/home1/sriram/panda/saved_models/half_fcn_t_fold-0_best.pth'
logfile = '/home1/sriram/panda/saved_models/log.txt'
warmup_epo = 1
n_epochs = 30
alpha = 0.4
device = torch.device('cuda:0')
df_biopsy.head()
sz = 256
N = 36


"""# K-fold CV"""

skf = StratifiedKFold(5, shuffle=True, random_state=42)
df_biopsy['fold'] = -1

for i, (train_idx, valid_idx) in enumerate(skf.split(df_biopsy, df_biopsy['isup_grade'])):
    df_biopsy.loc[valid_idx, 'fold'] = i
df_biopsy.head()

"""# Model"""

class enetv2(nn.Module):
    def __init__(self, enet_type, out_dim):
        super(enetv2, self).__init__()
        self.enet = model = EfficientNet.from_pretrained(enet_type, num_classes=out_dim)

    def forward(self, x):
        x = self.enet(x)
        return x

    def extract_endpoints(self, inputs):
        """Use convolution layer to extract features
        from reduction levels i in [1, 2, 3, 4, 5].
        Args:
            inputs (tensor): Input tensor.
        Returns:
            Dictionary of last intermediate features
            with reduction levels i in [1, 2, 3, 4, 5].
            Example:
                >>> import torch
                >>> from efficientnet.model import EfficientNet
                >>> inputs = torch.rand(1, 3, 224, 224)
                >>> model = EfficientNet.from_pretrained('efficientnet-b0')
                >>> endpoints = model.extract_features(inputs)
                >>> print(endpoints['reduction_1'].shape)  # torch.Size([1, 16, 112, 112])
                >>> print(endpoints['reduction_2'].shape)  # torch.Size([1, 24, 56, 56])
                >>> print(endpoints['reduction_3'].shape)  # torch.Size([1, 40, 28, 28])
                >>> print(endpoints['reduction_4'].shape)  # torch.Size([1, 112, 14, 14])
                >>> print(endpoints['reduction_5'].shape)  # torch.Size([1, 1280, 7, 7])
        """
        endpoints = dict()

        # Stem
        x = self.enet._swish(self.enet._bn0(self.enet._conv_stem(inputs)))
        prev_x = x

        # Blocks
        for idx, block in enumerate(self.enet._blocks):
            drop_connect_rate = self.enet._global_params.drop_connect_rate
            if drop_connect_rate:
                drop_connect_rate *= float(idx) / len(self.enet._blocks) # scale drop connect_rate
            x = block(x, drop_connect_rate=drop_connect_rate)
            if prev_x.size(2) > x.size(2):
                endpoints[f'reduction_{len(endpoints)+1}'] = prev_x
            prev_x = x

        # Head
        x = self.enet._swish(self.enet._bn1(self.enet._conv_head(x)))
        endpoints[f'reduction_{len(endpoints)+1}'] = x

        return endpoints



def get_upsampling_weight(in_channels, out_channels, kernel_size):
    """Make a 2D bilinear kernel suitable for upsampling"""
    factor = (kernel_size + 1) // 2
    if kernel_size % 2 == 1:
        center = factor - 1
    else:
        center = factor - 0.5
    og = np.ogrid[:kernel_size, :kernel_size]
    filt = (1 - abs(og[0] - center) / factor) * \
           (1 - abs(og[1] - center) / factor)
    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),
                      dtype=np.float64)
    weight[range(in_channels), range(out_channels), :, :] = filt
    return torch.from_numpy(weight).float()
class FCN8s_half(nn.Module):
    def __init__(self, n_class=3):
        super(FCN8s_half, self).__init__()
        # fc6
        self.clip_size = 1536
        self.fc6 = nn.Conv2d(1280, 1536, 2)
        self.relu6 = nn.ReLU(inplace=True)
        self.drop6 = nn.Dropout2d()

        # fc7
        self.fc7 = nn.Conv2d(1536, 1536, 1)
        self.relu7 = nn.ReLU(inplace=True)
        self.drop7 = nn.Dropout2d()

        self.score_fr = nn.Conv2d(1536, n_class, 1)
        self.score_pool3 = nn.Conv2d(256, n_class, 1)
        self.score_pool4 = nn.Conv2d(512, n_class, 1)

        self.upscore2 = nn.ConvTranspose2d(
            n_class, n_class, 4, stride=2, bias=False)
        self.upscore8 = nn.ConvTranspose2d(
            n_class, n_class, 16, stride=8, bias=False)
        self.upscore_pool4 = nn.ConvTranspose2d(
            n_class, n_class, 4, stride=2, bias=False)

        self._initialize_weights()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                torch.nn.init.xavier_uniform_(m.weight)
                # if m.bias is not None:
                #     torch.nn.init.xavier_uniform_(m.bias)
            if isinstance(m, nn.ConvTranspose2d):
                assert m.kernel_size[0] == m.kernel_size[1]
                initial_weight = get_upsampling_weight(
                    m.in_channels, m.out_channels, m.kernel_size[0])
                m.weight.data.copy_(initial_weight)

    def forward(self, x, pool3, pool4):
        h = x
        h = self.relu6(self.fc6(h))
        h = self.drop6(h)

        h = self.relu7(self.fc7(h))
        h = self.drop7(h)

        h = self.score_fr(h)
        h = self.upscore2(h)
        upscore2 = h  # 1/16
        #pool4 = torch.zeros([1, 512, 96, 96]).half().cuda()
        pool4 = pool4.repeat([1,5, 1, 1])[:, :512, :, :].half().cuda()
        h = self.score_pool4(pool4)
        # print('new1:' , end=':')
        # print(h.shape)
        # h = h[:, :, 5:5 + upscore2.size()[2], 5:5 + upscore2.size()[3]]
        score_pool4c = h  # 1/16

        h = upscore2 + score_pool4c  # 1/16
        # print(h.shape)
        h = self.upscore_pool4(h)
        upscore_pool4 = h  # 1/8
        # print(h.shape)
        #pool3 = torch.zeros([1, 256, 192, 192]).half().cuda()
        pool3 = pool3.repeat(1,7,1,1)[:,:256,:,:].half().cuda()
        h = self.score_pool3(pool3)
        # h = h[:, :,
        #       9:9 + upscore_pool4.size()[2],
        #       9:9 + upscore_pool4.size()[3]]
        score_pool3c = h  # 1/8

        h = upscore_pool4[:, :, 1:193, 1:193] + score_pool3c  # 1/8

        h = self.upscore8(h)
        h = h[:, :, 4:4 + self.clip_size, 4:4 + self.clip_size].contiguous()

        return h

"""#Dataset util"""

def tile(img, seg, type):
    result = []
    shape = img.shape
    if type == 'radboud':
      seg[seg == 2] = 1
      seg[seg == 3] = 2
      seg[seg == 4] = 2
      seg[seg == 5] = 2
    pad0, pad1 = (sz - shape[0] % sz) % sz, (sz - shape[1] % sz) % sz
    img = np.pad(img, [[pad0 // 2,pad0 - pad0 // 2], [pad1 // 2, pad1 - pad1 // 2], \
                      [0,0]], mode = 'constant', constant_values=255, )
    seg = np.pad(seg, [[pad0 // 2,pad0 - pad0 // 2], [pad1 // 2, pad1 - pad1 // 2]], mode = 'constant', constant_values=0,)
    img = img.reshape(img.shape[0] // sz, sz, img.shape[1] // sz, sz, 3)
    seg = seg.reshape(seg.shape[0] // sz, sz, seg.shape[1] // sz, sz)
    img = img.transpose(0, 2, 1, 3, 4).reshape(-1, sz, sz, 3)
    seg = seg.transpose(0, 2, 1, 3).reshape(-1, sz, sz)
    

    if len(img) < N:
        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]], mode = 'constant',constant_values=255)
    if len(seg) < N:
        seg = np.pad(seg,[[0,N-len(seg)],[0,0],[0,0]], mode = 'constant',constant_values=0)
    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]
    img = img[idxs]
    # print(len(seg), len(img))
    for i in range(len(img)):
        idx = idxs[i]
        result.append({'img':img[i], 'idx':i, 'seg': seg[idx]})
    return result

def process_and_save_image(img_path, typ):
    # if os.path.exists(os.path.join(BASE, OUT_TRAIN, basename(img_path[:-7]) + '_' + str(0) + '.jpeg')) and \
    # os.path.exists(os.path.join(BASE, OUT_TRAIN, basename(img_path[:-7]) + '_' + str(35) + '.jpeg')) :
    #   return
    full_image = skimage.io.imread(img_path)
    sample = img_path
    seg = full_image[:,:, 0]
    
    seg_img_name = sample.split('/')[-1][:-7] + '_mask_1.npz'
    seg_img_name = '0'*(43 - len(seg_img_name)) + seg_img_name

    if (not os.path.exists(os.path.join(SEG_BASE, SEG, seg_img_name))):
      print(seg_img_name)
    else:
    
      seg = scipy.sparse.load_npz(os.path.join(SEG_BASE, SEG, seg_img_name))
      seg = seg.todense()
  
    # typ = get_type(sample)
    tiles = tile(full_image, seg, typ)

    
    # for t in tiles:
    #     img, idx = t['img'], t['idx']
    #     save_path = join(BASE, OUT_TRAIN, basename(img_path[:-7]) + '_' + str(idx) + '.jpeg')
    #     skimage.io.imsave(save_path, img, check_contrast=False)
    # if (not os.path.exists(os.path.join(SEG_BASE, SEG, seg_img_name))):
    #   return
    
    
    tiles1 = [tiles[i]['img'] for i in range(N)]
    # tiles = tile(img, seg, typ)
    tiles = [tiles[i]['seg'] for i in range(N)]
    n_rows = int(np.sqrt(N))
    tiled_image = []
    big_image = []
    for i in range(n_rows):
        tiled_image.append(np.concatenate(tiles[n_rows*i:n_rows*i \
                                                + n_rows], axis=1))
        big_image.append(np.concatenate(tiles1[n_rows*i:n_rows*i \
                                                    + n_rows], axis=1))
    tiled_image = np.concatenate(tiled_image, axis=0)
    big_image = np.concatenate(big_image, axis=0)
    return big_image, tiled_image
    # image_mask = scipy.sparse.csc_matrix(tiled_image)
    # scipy.sparse.save_npz(os.path.join(SEG_BASE, OUT_SEG, os.path.basename(seg_img_name)), image_mask)

"""# Dataset"""

class PANDADataset(Dataset):
    def __init__(self,
                 df,
                 image_folder,
                 n_tiles,
                 transform=None,
                ):

        self.df = df.reset_index(drop=True)
        self.image_folder = image_folder
        self.n_tiles = n_tiles        
        self.transform = transform

    def __len__(self):
        # print(self.df.shape[0])
        return self.df.shape[0]
    
    def read_tiles(self, img_id):
        tiles = []
        for i in range(self.n_tiles):
            # img_path = os.path.join(self.image_folder, \
            img_path = os.path.join(BASE, OUT_TRAIN, img_id[:2], \
                                    '{}_{}.jpeg'.format(img_id, i))
            # print(img_path)
            tiles.append(skimage.io.imread(img_path))
        return tiles

    def __getitem__(self, index):
        row = self.df.iloc[index]
        img_id = row.image_id 
        
        #tiles = self.read_tiles(img_id)
        
        #idxes = list(range(self.n_tiles))
        #n_rows = int(np.sqrt(self.n_tiles))



        tiled_image, mask = process_and_save_image(os.path.join(BASE, TRAIN, img_id + '_1.jpeg'), row.data_provider)
        tiled_image = Image.fromarray(tiled_image)
        mask = torch.tensor(mask, dtype=torch.uint8)
        
        # if np.random.rand() < 0.5:
        #   tiled_image = ImageOps.flip(tiled_image)
        #   mask = torch.flip(mask, )
        # if np.random.rand() < 0.5:
        #   tiled_image = ImageOps.rotate(tiled_image)
        #   mask = ImageOps.rotate(mask)
        if self.transform is not None:
            tiled_image = self.transform(tiled_image)
            # mask =  self.transform(mask)
        label = np.zeros(out_dim).astype(np.float32)
        label[:row.isup_grade] = 1.
        return (tiled_image).half(), torch.tensor(label), mask.long()



"""# Transformations"""

mean = [0.90949707, 0.8188697, 0.87795304]
std = [0.36357649, 0.49984502, 0.40477625]

transform_train = transforms.Compose([
    # transforms.RandomHorizontalFlip(p=0.5),
    # transforms.RandomVerticalFlip(p=0.5),
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])
transform_val = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

"""# Creating Model, Dataloader and optimizer"""

# using one fold for training
#df_train, df_valid = np.split(df_biopsy.sample(frac=1), [int(.9*len(df_biopsy))])
#df_train  = df_biopsy.loc[train_idx]
#df_valid = df_biopsy.loc[valid_idx]


valid_idx = df_biopsy['fold'] == 0
train_idx = df_biopsy['fold'] > 0
df_valid = df_biopsy.loc[valid_idx]
df_train = df_biopsy.loc[train_idx]
dataset_train =  PANDADataset(df_train,  image_folder, n_tiles, transform=transform_train)

dataset_valid = PANDADataset(df_valid,  image_folder, n_tiles, transform=transform_val)
train_loader = DataLoader(dataset_train, 
                          batch_size=batch_size, 
                          sampler=RandomSampler(dataset_train),
                          num_workers=num_workers)
valid_loader = DataLoader(dataset_valid,
                          batch_size=batch_size,
                          sampler=SequentialSampler(dataset_valid),
                          num_workers=num_workers)
# scaler = GradScaler()
model = enetv2(enet_type, out_dim=out_dim)
# model.half()  # convert to half precision
for layer in model.modules():
  if isinstance(layer, nn.BatchNorm2d):
    layer.float()
model2 = FCN8s_half(n_class=3)
# model2.half()  # convert to half precision
# for layer in model2.modules():
#   if isinstance(layer, nn.BatchNorm2d):
#     layer.float()


dicti = torch.load(pretrained)
model.load_state_dict({k[7:]:dicti['model'][k] for k in dicti['model'].keys()})
dicti = torch.load(pretrained2)
model2.load_state_dict({k[7:]:dicti['model'][k] for k in dicti['model'].keys()})
optimizer = optim.Adam(set(model.parameters()) | set(model2.parameters()), lr=init_lr/warmup_factor)
model = model.to(device)
model2 = model2.to(device)
model3, optimizer = amp.initialize([model, model2], optimizer, opt_level="O1") 
# optimizer2 = optim.Adam(model.parameters(), lr=init_lr/warmup_factor)

model  = nn.DataParallel(model3[0])
model2 = nn.DataParallel(model3[1])
scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs-warmup_epo)
scheduler = GradualWarmupScheduler(optimizer, multiplier=warmup_factor, \
                                   total_epoch=warmup_epo, after_scheduler=scheduler_cosine)

criterion = nn.BCEWithLogitsLoss()
criterion2 = nn.CrossEntropyLoss()
print("Number of train   samples : {}".format(len(dataset_train)))
print("Number of validation samples : {}".format(len(dataset_valid)))


best_model = '{}_t_fold-{}_best.pth'.format(kernel_type, fold)

best_model2 = '{}_t_fold-{}_best.pth'.format(kernel_type2, fold)
last_model = '{}_t_fold-{}_last.pth'.format(kernel_type, fold)

last_model2 = '{}_t_fold-{}_last.pth'.format(kernel_type2, fold)
final_model = '{}_t_fold-{}_final.pth'.format(kernel_type, fold) 
save_path = os.path.join('/home1/sriram/panda/', 'saved_models')
save_path2 = save_path
qwk_max = 0.
loss2_min = np.inf

"""# Train and Val"""

def train_epoch(loader, optimizer, valid_loader, epoch):

    model.train()
    model2.train()
    train_loss = []
    bar = tqdm(loader)

    batch_n = 1
    for (data, target, target_mask) in bar:
        data, target, target_mask = data.to(device), target.to(device), target_mask.to(device)

        optimizer.zero_grad()
        logits = model(data)
        m = model.module.extract_endpoints(data)
        out1 = model.module.enet.extract_features(data).half()
        out2 = m['reduction_3'].half()
        out3 = m['reduction_4'].half()
        out = model2(out1, out2, out3)  

        loss = criterion(logits, target)
        # loss2 = loss
        loss2 = criterion2(out, target_mask)
        # print(out.shape)
        loss3 = (alpha) * loss + (1 - alpha) * loss2
        # print(torch.min(out.detach()), torch.min(target_mask).detach())

        # print(torch.max(out.detach()), torch.max(target_mask).detach())
        # print(out[0,:5,:5], target_mask[0,:5,:5])
        # print(loss2)
        # loss3 = loss
        # loss3.backward()
        with amp.scale_loss(loss3, optimizer) as scaled_loss:
          scaled_loss.backward()

        loss1_np = loss.detach().cpu().numpy()
        loss2_np = loss2.detach().cpu().numpy()
        loss3_np = loss3.detach().cpu().numpy()
        # scaler.update()
        train_loss.append(loss3_np)
        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)
        bar.set_description('%.3f, %.3f, %.2f, %.2f' % (loss1_np, loss2_np, loss3_np, smooth_loss))
        if batch_n % 2000 == 10:
          val_epoch(valid_loader, epoch, train_loss, batch_n)
        batch_n += 1
    return train_loss


def val_epoch(loader, epoch, train_loss, batch_n):
    global loss2_min, qwk_max
    model.eval()
    model2.eval()
    val_loss = []
    PREDS = []
    TARGETS = []
    
    with torch.no_grad():
        for (data, target, target_mask) in tqdm(loader):
            data, target, target_mask = data.to(device), target.to(device), target_mask.to(device)
            logits = model(data)
            m = model.module.extract_endpoints(data)
            out1 = model.module.enet.extract_features(data).half()
            out2 = m['reduction_3'].half()
            out3 = m['reduction_4'].half()
            #[1, 40, 192, 192]) torch.Size([1, 112, 96, 96])
            # out2 = torch.zeros(out.shape[0], 40, 192, 192)
            # out3 = torch.zeros(out.shape[0], 112, 96, 96)
            
            loss = criterion(logits, target)

            out = model2(out1, out2, out3)
            pred = logits.sigmoid().sum(1).detach().round()            
            loss2 = criterion2(out, target_mask)
            PREDS.append(pred)
            TARGETS.append(target.sum(1))

            val_loss.append(loss.detach().cpu().numpy())
        val_loss = np.mean(val_loss)

    PREDS = torch.cat(PREDS).cpu().numpy()
    TARGETS = torch.cat(TARGETS).cpu().numpy()
    acc = (PREDS == TARGETS).mean() * 100.
    
    qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')
    qwk_k = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'karolinska'], \
                              df_valid[df_valid['data_provider'] == 'karolinska'].isup_grade.values,\
                              weights='quadratic')
    qwk_r = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'radboud'], \
                              df_valid[df_valid['data_provider'] == 'radboud'].isup_grade.values,\
                              weights='quadratic')
    print('qwk', qwk, 'qwk_k', qwk_k, 'qwk_r', qwk_r)

    content = "{}, Epoch {}, batch {}, lr: {:.7f}, train loss: {:.5f}," \
              " val loss: {:.5f}, acc: {:.5f}, qwk: {:.5f}".format(
                  time.ctime(), epoch, batch_n, optimizer.param_groups[0]["lr"], 
                  np.mean(train_loss), np.mean(val_loss), acc, qwk
              )
    print(content)
    with open(logfile, 'a') as appender:
    # with open('log_{}_fold-{}.txt'.format(kernel_type, fold), 'a') as appender:
        appender.write(content + '\n')

    if loss2 < loss2_min:
        checkpoint = {
          'model': model2.state_dict(),
          'optimizer': optimizer.state_dict(),
          'amp': amp.state_dict()
        }
        torch.save(checkpoint, os.path.join(save_path2, best_model2))
        # torch.save(model2.state_dict(), os.path.join(save_path2, best_model2))
        loss2_min = loss2

    checkpoint = {
          'model': model2.state_dict(),
          'optimizer': optimizer.state_dict(),
          'amp': amp.state_dict()
    }
    torch.save(checkpoint, os.path.join(save_path2, last_model2))
    if qwk > qwk_max:
        print('score2 ({:.6f} --> {:.6f}).  Saving model ...'.format(qwk_max, qwk))
        checkpoint = {
          'model': model.state_dict(),
          'optimizer': optimizer.state_dict(),
          'amp': amp.state_dict()
        }
        torch.save(checkpoint, os.path.join(save_path, best_model))
        
        qwk_max = qwk    
    checkpoint = {
          'model': model.state_dict(),
          'optimizer': optimizer.state_dict(),
          'amp': amp.state_dict()
    }
    torch.save(checkpoint, os.path.join(save_path, last_model))
        # torch.save(model.state_dict(), os.path.join(save_path, best_model))
        
    return val_loss, acc, qwk, loss2

def train():

  for epoch in range(0, n_epochs):
      print(time.ctime(), 'Epoch:', epoch)

      train_loss = train_epoch(train_loader, optimizer, valid_loader, epoch)
      scheduler.step(epoch-1)
      val_loss, acc, qwk, loss2 = val_epoch(valid_loader, epoch, train_loss, 100000)

      

  torch.save(model.state_dict(), os.path.join(save_path, final_model))



def test():
  img_id, p = df_biopsy.iloc[0].image_id, df_biopsy.iloc[0].data_provider
  tiled_image, mask = process_and_save_image(os.path.join(BASE, TRAIN,  img_id + '_1.jpeg'), p)
  plt.imsave('test.png', tiled_image)
  plt.imsave('test2.png', mask/2.0)



#l = dataset_train[4]
test()

train()
